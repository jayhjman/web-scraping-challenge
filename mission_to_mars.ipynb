{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import scraping libraries and anything else needed\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Initializing the splinter browser plug in\n",
    "#\n",
    "def init_browser():\n",
    "    # @NOTE: My chromedriver is on the system PATH for this to work\n",
    "    executable_path = {\"executable_path\": \"chromedriver.exe\"}\n",
    "    return Browser(\"chrome\", **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Go to https://mars.nasa.gov/news/ and scrape the latest mars news\n",
    "#\n",
    "def scrape_mars_news():\n",
    "    \n",
    "    browser = init_browser()\n",
    "\n",
    "    # Visit https://mars.nasa.gov/news/\n",
    "    url = \"https://mars.nasa.gov/news/\"\n",
    "    browser.visit(url)\n",
    "\n",
    "    #  Delay so we can finish reading the page\n",
    "    time.sleep(1)\n",
    "\n",
    "    # Scrape page into Soup\n",
    "    html = browser.html\n",
    "    soup = bs(html, \"html.parser\")\n",
    "\n",
    "    # Grab the list of news articles\n",
    "    news_snippet = soup.find(\"ul\", class_=\"item_list\")\n",
    "    \n",
    "    # print(news_snippet.prettify())\n",
    "    \n",
    "    # The articles are contained in a list of slides\n",
    "    slide_list = soup.find_all(\"li\", class_=\"slide\")\n",
    "\n",
    "    # grab the first slide as it is the latest article\n",
    "    news_p = slide_list[0].find(\"div\", class_ =\"rollover_description_inner\").get_text()\n",
    "    news_title = slide_list[0].find(\"h3\").get_text()\n",
    "\n",
    "    # Quit the browser after scraping\n",
    "    browser.quit()\n",
    "\n",
    "    # Return results\n",
    "    return {\n",
    "        \"news_title\": news_title,\n",
    "        \"news_p\": news_p,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'news_p': \"The symbols, mottos, and small objects added to the agency's \"\n",
      "           'newest Mars rover serve a variety of purposes, from functional to '\n",
      "           'decorative.',\n",
      " 'news_title': \"5 Hidden Gems Are Riding Aboard NASA's Perseverance Rover\"}\n"
     ]
    }
   ],
   "source": [
    "mars_news = scrape_mars_news()\n",
    "\n",
    "pprint(mars_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Go to https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars and scrape the featured image\n",
    "#\n",
    "# This does change time to time so don't be surprised if it changes between calls\n",
    "#\n",
    "def scrape_mars_featured_image():\n",
    "    \n",
    "    browser = init_browser()\n",
    "\n",
    "    # Visit https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\n",
    "    url = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "    browser.visit(url)\n",
    "\n",
    "    # Delay so we can finish reading the page\n",
    "    time.sleep(1)\n",
    "\n",
    "    # Scrape page into Soup\n",
    "    html = browser.html\n",
    "    soup = bs(html, \"html.parser\")\n",
    "\n",
    "    # Get the full_image link to further traverse down \n",
    "    image_snippet = soup.find(\"a\", id=\"full_image\")\n",
    "    \n",
    "    # data-link has a landing page that can be used to get the full image link\n",
    "    image_link = image_snippet[\"data-link\"]\n",
    "    image_link = url.split(\"/spaceimages\")[0] + image_link\n",
    "    \n",
    "    # print(image_snippet.prettify())\n",
    "    # print(image_link)\n",
    "    \n",
    "    # Go to the page where we can get the full image\n",
    "    browser.visit(image_link)\n",
    "    \n",
    "    # Delay so we can finish reading the page\n",
    "    time.sleep(1)\n",
    "\n",
    "    # Scrape page into Soup\n",
    "    html = browser.html    \n",
    "    soup = bs(html, \"html.parser\")\n",
    "    \n",
    "    # Find the image tag with the main image and build the final link to the image\n",
    "    full_image_snippet = soup.find(\"img\", class_=\"main_image\")\n",
    "    full_image_link = url.split(\"/spaceimages\")[0] + full_image_snippet[\"src\"]\n",
    "    \n",
    "    # print(full_image_link)\n",
    "    \n",
    "    # Quit the browser after scraping\n",
    "    browser.quit()\n",
    "\n",
    "    # Return results\n",
    "    return full_image_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.jpl.nasa.gov/spaceimages/images/largesize/PIA18899_hires.jpg\n"
     ]
    }
   ],
   "source": [
    "print(scrape_mars_featured_image())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
